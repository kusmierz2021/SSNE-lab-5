{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\przek\\AppData\\Local\\Temp\\ipykernel_91124\\2949133806.py:5: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    }
   ],
   "source": [
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "sns.set()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import torchvision\n",
    "import shutil\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_all_seeds(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Oversampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "def over_sample(path):\n",
    "    classes = os.listdir(path)\n",
    "    num_class = {}\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        num_of_class = len(os.listdir(f\"{path}/{classes[i]}\"))\n",
    "        num_class[classes[i]] = num_of_class\n",
    "\n",
    "    max_num_class = max(num_class.values())\n",
    "\n",
    "    for key in num_class:\n",
    "        copy_all = max_num_class // num_class[key] - 1\n",
    "        copy_sample = max_num_class % num_class[key]\n",
    "\n",
    "        images = os.listdir(f\"{path}/{key}\")\n",
    "        to_copy_sample = random.sample(images, k=copy_sample)\n",
    "        ind = 0\n",
    "        for i in range(copy_all):\n",
    "            for image in images:\n",
    "\n",
    "                shutil.copytree(f\"{path}/{key}/{image}\", f\"{path}/{key}/{image}_{i}\")\n",
    "            ind += 1\n",
    "        for image in to_copy_sample:\n",
    "            shutil.copytree(f\"{path}/{key}/{image}\", f\"{path}/{key}/{image}_{ind}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create val folder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "def create_val_folder():\n",
    "    sub_folders = os.listdir(\"./trafic_32\")\n",
    "    os.mkdir(\"./val_trafic_32\")\n",
    "    for sub_folder in sub_folders:\n",
    "        os.mkdir(f\"./val_trafic_32/{sub_folder}\")\n",
    "\n",
    "    for sub_folder in sub_folders:\n",
    "        images_list = os.listdir(f\"./trafic_32/{sub_folder}\")\n",
    "        to_move = random.sample(images_list, k=(len(images_list) // 5))\n",
    "        for image in to_move:\n",
    "            shutil.move(f\"./trafic_32/{sub_folder}/{image}\", f\"./val_trafic_32/{sub_folder}/{image}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "def check_classes_amounts(path):\n",
    "    classes = os.listdir(path)\n",
    "    num_all = 0\n",
    "    num_class = []\n",
    "    for i in range(len(classes)):\n",
    "        num_of_class = len(os.listdir(f\"{path}/{classes[i]}\"))\n",
    "        num_class.append(num_of_class)\n",
    "        num_all += num_of_class\n",
    "    print(f\"Number of all examples: {num_all}\\nNumbers of every class: {num_class}\")\n",
    "    # return num_all, num_class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all examples: 77400\n",
      "Numbers of every class: [1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800]\n"
     ]
    }
   ],
   "source": [
    "check_classes_amounts(\"./trafic_32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "# create_val_folder()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all examples: 7841\n",
      "Numbers of every class: [42, 444, 450, 282, 396, 372, 84, 288, 282, 294, 402, 264, 420, 432, 156, 126, 84, 222, 240, 42, 72, 66, 78, 102, 54, 300, 120, 48, 108, 54, 90, 156, 48, 137, 84, 240, 78, 42, 414, 60, 72, 48, 48]\n"
     ]
    }
   ],
   "source": [
    "check_classes_amounts(\"./val_trafic_32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all examples: 77400\n",
      "Numbers of every class: [1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800]\n"
     ]
    }
   ],
   "source": [
    "check_classes_amounts(\"./trafic_32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "# over_sample(\"./trafic_32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all examples: 77400\n",
      "Numbers of every class: [1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800]\n"
     ]
    }
   ],
   "source": [
    "check_classes_amounts(\"./trafic_32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\"trafic_32/\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "\n",
    "\n",
    "val_dataset = datasets.ImageFolder(\"val_trafic_32/\", transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, drop_last=False, num_workers=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "# does not work after transfation from image format to tensor\n",
    "# from IPython.display import display\n",
    "#\n",
    "# image_num = 31367\n",
    "# scale = 4\n",
    "# display(train_dataset[image_num][0].resize(( int(train_dataset[image_num][0].width * scale), int(train_dataset[image_num][0].height * scale))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Net preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.fc_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_mean  = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_var   = nn.Linear (hidden_dim, latent_dim)\n",
    "\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.training = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x       = self.LeakyReLU(self.fc_1(x))\n",
    "        x       = self.LeakyReLU(self.fc_2(x))\n",
    "        mean     = self.fc_mean(x)\n",
    "        log_var  = self.fc_var(x)\n",
    "\n",
    "        return mean, log_var"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc_1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h     = self.LeakyReLU(self.fc_1(x))\n",
    "        h     = self.LeakyReLU(self.fc_2(h))\n",
    "\n",
    "        x_hat = torch.sigmoid(self.fc_3(h))\n",
    "        # x_hat = x_hat.view([-1, 1, 28, 28])\n",
    "        x_hat = x_hat.view([-1, 3, 32, 32])\n",
    "        return x_hat\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "        self.decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = x_dim)\n",
    "\n",
    "\n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(device)        # sampling epsilon\n",
    "        z = mean + var * epsilon\n",
    "        return z\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.encoder(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, mean, log_var"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "def vae_loss_function(x, x_hat, mean, log_var):\n",
    "\n",
    "\n",
    "    reproduction_loss = nn.functional.mse_loss(x_hat, x, reduction='sum')\n",
    "    if reproduction_loss.item() < 99999:\n",
    "        pass\n",
    "    else:\n",
    "        reproduction_loss.item = 99999\n",
    "    # print(f\"rep_loss -> {reproduction_loss}\")\n",
    "    KLD      = min(99999, -0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp()))\n",
    "    # print(f\"KLD -> {KLD}\")\n",
    "\n",
    "    return reproduction_loss + KLD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [],
   "source": [
    "vae = VAE(latent_dim=512, hidden_dim=2048, x_dim=3072).to(device)\n",
    "# vae.load_state_dict(torch.load(\"SSNE-lab-5/vae_40\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.99)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 302/302 [00:27<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 32638.182371430048, test L1 = 0.11167529609895521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 302/302 [00:28<00:00, 10.51it/s]\n",
      "100%|██████████| 302/302 [00:29<00:00, 10.21it/s]\n",
      "100%|██████████| 302/302 [00:37<00:00,  7.96it/s]\n",
      "100%|██████████| 302/302 [00:47<00:00,  6.35it/s]\n",
      "100%|██████████| 302/302 [01:04<00:00,  4.66it/s]\n",
      "100%|██████████| 302/302 [01:42<00:00,  2.93it/s]\n",
      "100%|██████████| 302/302 [01:09<00:00,  4.36it/s]\n",
      "100%|██████████| 302/302 [00:51<00:00,  5.81it/s]\n",
      "100%|██████████| 302/302 [00:39<00:00,  7.70it/s]\n",
      "100%|██████████| 302/302 [00:38<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss 13744.962428212955, test L1 = 0.07896302376062639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 302/302 [00:31<00:00,  9.54it/s]\n",
      "100%|██████████| 302/302 [00:31<00:00,  9.54it/s]\n",
      "100%|██████████| 302/302 [00:32<00:00,  9.20it/s]\n",
      "100%|██████████| 302/302 [00:33<00:00,  9.04it/s]\n",
      "100%|██████████| 302/302 [00:29<00:00, 10.35it/s]\n",
      " 47%|████▋     | 142/302 [00:14<00:14, 10.86it/s]"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "for n in range(num_epochs):\n",
    "    losses_epoch = []\n",
    "    for x, _ in tqdm(iter(train_loader)):\n",
    "        x = x.to(device)\n",
    "        out, means, log_var = vae(x)\n",
    "        loss = vae_loss_function(x, out, means, log_var)\n",
    "        losses_epoch.append(loss.item())\n",
    "        loss.backward()               # backward pass (compute parameter updates)\n",
    "        optimizer.step()              # make the updates for each parameter\n",
    "        optimizer.zero_grad()\n",
    "    L1_list = []\n",
    "    if n % 10 == 0:\n",
    "        for x, _ in iter(val_loader):\n",
    "            x  = x.to(device)\n",
    "            out, _, _ = vae(x)\n",
    "            L1_list.append(torch.mean(torch.abs(out-x)).item())\n",
    "        print(f\"Epoch {n} loss {np.mean(np.array(losses_epoch))}, test L1 = {np.mean(L1_list)}\")\n",
    "    scheduler.step()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(vae.state_dict(), \"vae_40_os_512_2048_bs256\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# vae.load_state_dict(torch.load(\"vae_40_after_os\"))\n",
    "# vae.state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_train_images(start, num):\n",
    "    return torch.stack([val_dataset[i][0] for i in range(start,start+num)], dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def visualize_reconstructions(model, input_imgs, device):\n",
    "    # Reconstruct images\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        reconst_imgs, means, log_var = model(input_imgs.to(device))\n",
    "    reconst_imgs = reconst_imgs.cpu()\n",
    "\n",
    "    # Plotting\n",
    "    imgs = torch.stack([input_imgs, reconst_imgs], dim=1).flatten(0,1)\n",
    "    grid = torchvision.utils.make_grid(imgs, nrow=4, normalize=False, range=(-1,1))\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    if len(input_imgs) == 4:\n",
    "        plt.figure(figsize=(10,10))\n",
    "    else:\n",
    "        plt.figure(figsize=(15,10))\n",
    "    plt.title(f\"Reconstructions\")\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(13):\n",
    "    # input_imgs = get_train_images(6765, 8)\n",
    "    input_imgs = get_train_images(i * 500, 8)\n",
    "    visualize_reconstructions(vae, input_imgs, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_images(model, n_imgs, device):\n",
    "    # Generate images\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        generated_imgs = model.decoder(torch.randn([n_imgs, model.latent_dim]).to(device))\n",
    "    generated_imgs = generated_imgs.cpu()\n",
    "\n",
    "    grid = torchvision.utils.make_grid(generated_imgs, nrow=4, normalize=False, range=(-1,1))\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    if len(input_imgs) == 4:\n",
    "        plt.figure(figsize=(10,10))\n",
    "    else:\n",
    "        plt.figure(figsize=(15,10))\n",
    "    plt.title(f\"Generations\")\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generate_images(vae, 16 , device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}