{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\przek\\AppData\\Local\\Temp\\ipykernel_69868\\2949133806.py:5: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    }
   ],
   "source": [
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "sns.set()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import torchvision\n",
    "import shutil\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_all_seeds(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Oversampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "def over_sample(path):\n",
    "    classes = os.listdir(path)\n",
    "    num_class = {}\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        num_of_class = len(os.listdir(f\"{path}/{classes[i]}\"))\n",
    "        num_class[classes[i]] = num_of_class\n",
    "\n",
    "    max_num_class = max(num_class.values())\n",
    "\n",
    "    for key in num_class:\n",
    "        copy_all = max_num_class // num_class[key] - 1\n",
    "        copy_sample = max_num_class % num_class[key]\n",
    "\n",
    "        images = os.listdir(f\"{path}/{key}\")\n",
    "        to_copy_sample = random.sample(images, k=copy_sample)\n",
    "        ind = 0\n",
    "        for i in range(copy_all):\n",
    "            for image in images:\n",
    "\n",
    "                shutil.copytree(f\"{path}/{key}/{image}\", f\"{path}/{key}/{image}_{i}\")\n",
    "            ind += 1\n",
    "        for image in to_copy_sample:\n",
    "            shutil.copytree(f\"{path}/{key}/{image}\", f\"{path}/{key}/{image}_{ind}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create val folder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "def create_val_folder():\n",
    "    sub_folders = os.listdir(\"./trafic_32\")\n",
    "    os.mkdir(\"./val_trafic_32\")\n",
    "    for sub_folder in sub_folders:\n",
    "        os.mkdir(f\"./val_trafic_32/{sub_folder}\")\n",
    "\n",
    "    for sub_folder in sub_folders:\n",
    "        images_list = os.listdir(f\"./trafic_32/{sub_folder}\")\n",
    "        to_move = random.sample(images_list, k=(len(images_list) // 5))\n",
    "        for image in to_move:\n",
    "            shutil.move(f\"./trafic_32/{sub_folder}/{image}\", f\"./val_trafic_32/{sub_folder}/{image}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def check_classes_amounts(path):\n",
    "    classes = os.listdir(path)\n",
    "    num_all = 0\n",
    "    num_class = []\n",
    "    for i in range(len(classes)):\n",
    "        num_of_class = len(os.listdir(f\"{path}/{classes[i]}\"))\n",
    "        num_class.append(num_of_class)\n",
    "        num_all += num_of_class\n",
    "    print(f\"Number of all examples: {num_all}\\nNumbers of every class: {num_class}\")\n",
    "    # return num_all, num_class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all examples: 39209\n",
      "Numbers of every class: [210, 2220, 2250, 1410, 1980, 1860, 420, 1440, 1410, 1470, 2010, 1320, 2100, 2160, 780, 630, 420, 1110, 1200, 210, 360, 330, 390, 510, 270, 1500, 600, 240, 540, 270, 450, 780, 240, 689, 420, 1200, 390, 210, 2070, 300, 360, 240, 240]\n"
     ]
    }
   ],
   "source": [
    "check_classes_amounts(\"./trafic_32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "# create_val_folder()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all examples: 7841\n",
      "Numbers of every class: [42, 444, 450, 282, 396, 372, 84, 288, 282, 294, 402, 264, 420, 432, 156, 126, 84, 222, 240, 42, 72, 66, 78, 102, 54, 300, 120, 48, 108, 54, 90, 156, 48, 137, 84, 240, 78, 42, 414, 60, 72, 48, 48]\n"
     ]
    }
   ],
   "source": [
    "check_classes_amounts(\"./val_trafic_32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all examples: 31368\n",
      "Numbers of every class: [168, 1776, 1800, 1128, 1584, 1488, 336, 1152, 1128, 1176, 1608, 1056, 1680, 1728, 624, 504, 336, 888, 960, 168, 288, 264, 312, 408, 216, 1200, 480, 192, 432, 216, 360, 624, 192, 552, 336, 960, 312, 168, 1656, 240, 288, 192, 192]\n"
     ]
    }
   ],
   "source": [
    "check_classes_amounts(\"./trafic_32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "over_sample(\"./trafic_32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all examples: 77400\n",
      "Numbers of every class: [1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800]\n"
     ]
    }
   ],
   "source": [
    "check_classes_amounts(\"./trafic_32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\"trafic_32/\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "\n",
    "\n",
    "val_dataset = datasets.ImageFolder(\"val_trafic_32/\", transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, drop_last=False, num_workers=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# does not work after transfation from image format to tensor\n",
    "# from IPython.display import display\n",
    "#\n",
    "# image_num = 31367\n",
    "# scale = 4\n",
    "# display(train_dataset[image_num][0].resize(( int(train_dataset[image_num][0].width * scale), int(train_dataset[image_num][0].height * scale))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Net preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.fc_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_mean  = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_var   = nn.Linear (hidden_dim, latent_dim)\n",
    "\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.training = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x       = self.LeakyReLU(self.fc_1(x))\n",
    "        x       = self.LeakyReLU(self.fc_2(x))\n",
    "        mean     = self.fc_mean(x)\n",
    "        log_var  = self.fc_var(x)\n",
    "\n",
    "        return mean, log_var"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc_1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h     = self.LeakyReLU(self.fc_1(x))\n",
    "        h     = self.LeakyReLU(self.fc_2(h))\n",
    "\n",
    "        x_hat = torch.sigmoid(self.fc_3(h))\n",
    "        # x_hat = x_hat.view([-1, 1, 28, 28])\n",
    "        x_hat = x_hat.view([-1, 3, 32, 32])\n",
    "        return x_hat\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "        self.decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = x_dim)\n",
    "\n",
    "\n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(device)        # sampling epsilon\n",
    "        z = mean + var * epsilon\n",
    "        return z\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.encoder(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, mean, log_var"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def vae_loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.mse_loss(x_hat, x, reduction='sum')\n",
    "    KLD      = -0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return reproduction_loss + KLD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "vae = VAE(latent_dim=256, hidden_dim=2048, x_dim=3072).to(device)\n",
    "# vae.load_state_dict(torch.load(\"SSNE-lab-5/vae_40\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.99)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:32<21:16, 32.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 37447.79149590164, test L1 = 0.12352404719398867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 11/40 [03:21<09:04, 18.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss 15041.328517225922, test L1 = 0.08206072726076649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 21/40 [07:44<08:11, 25.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 loss 13719.756259605532, test L1 = 0.07787744869147578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [11:01<03:04, 20.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 loss 13003.81335649334, test L1 = 0.07414149517013181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [13:34<00:00, 20.35s/it]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SSNE-lab-5/vae_40'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [17], line 21\u001B[0m\n\u001B[0;32m     18\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m loss \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnp\u001B[38;5;241m.\u001B[39mmean(np\u001B[38;5;241m.\u001B[39marray(losses_epoch))\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, test L1 = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnp\u001B[38;5;241m.\u001B[39mmean(L1_list)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     19\u001B[0m     scheduler\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 21\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvae\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSSNE-lab-5/vae_40\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\VI sem\\SSNE\\laby_ssne\\lib\\site-packages\\torch\\serialization.py:376\u001B[0m, in \u001B[0;36msave\u001B[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001B[0m\n\u001B[0;32m    340\u001B[0m \u001B[38;5;124;03m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001B[39;00m\n\u001B[0;32m    341\u001B[0m \n\u001B[0;32m    342\u001B[0m \u001B[38;5;124;03mSaves an object to a disk file.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    372\u001B[0m \u001B[38;5;124;03m    >>> torch.save(x, buffer)\u001B[39;00m\n\u001B[0;32m    373\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    374\u001B[0m _check_dill_version(pickle_module)\n\u001B[1;32m--> 376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m    377\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _use_new_zipfile_serialization:\n\u001B[0;32m    378\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m _open_zipfile_writer(opened_file) \u001B[38;5;28;01mas\u001B[39;00m opened_zipfile:\n",
      "File \u001B[1;32m~\\Desktop\\VI sem\\SSNE\\laby_ssne\\lib\\site-packages\\torch\\serialization.py:230\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    228\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[1;32m--> 230\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    231\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    232\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[1;32m~\\Desktop\\VI sem\\SSNE\\laby_ssne\\lib\\site-packages\\torch\\serialization.py:211\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[1;32m--> 211\u001B[0m     \u001B[38;5;28msuper\u001B[39m(_open_file, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'SSNE-lab-5/vae_40'"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "for n in tqdm(range(num_epochs)):\n",
    "    losses_epoch = []\n",
    "    for x, _ in iter(train_loader):\n",
    "        x = x.to(device)\n",
    "        out, means, log_var = vae(x)\n",
    "        loss = vae_loss_function(x, out, means, log_var)\n",
    "        losses_epoch.append(loss.item())\n",
    "        loss.backward()               # backward pass (compute parameter updates)\n",
    "        optimizer.step()              # make the updates for each parameter\n",
    "        optimizer.zero_grad()\n",
    "    L1_list = []\n",
    "    if n % 10 == 0:\n",
    "        for x, _ in iter(val_loader):\n",
    "            x  = x.to(device)\n",
    "            out, _, _ = vae(x)\n",
    "            L1_list.append(torch.mean(torch.abs(out-x)).item())\n",
    "        print(f\"Epoch {n} loss {np.mean(np.array(losses_epoch))}, test L1 = {np.mean(L1_list)}\")\n",
    "    scheduler.step()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "torch.save(vae.state_dict(), \"vae_40\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_train_images(start, num):\n",
    "    return torch.stack([val_dataset[i][0] for i in range(start,start+num)], dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def visualize_reconstructions(model, input_imgs, device):\n",
    "    # Reconstruct images\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        reconst_imgs, means, log_var = model(input_imgs.to(device))\n",
    "    reconst_imgs = reconst_imgs.cpu()\n",
    "\n",
    "    # Plotting\n",
    "    imgs = torch.stack([input_imgs, reconst_imgs], dim=1).flatten(0,1)\n",
    "    grid = torchvision.utils.make_grid(imgs, nrow=4, normalize=False, range=(-1,1))\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    if len(input_imgs) == 4:\n",
    "        plt.figure(figsize=(10,10))\n",
    "    else:\n",
    "        plt.figure(figsize=(15,10))\n",
    "    plt.title(f\"Reconstructions\")\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_imgs = get_train_images(6765, 8)\n",
    "visualize_reconstructions(vae, input_imgs, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_images(model, n_imgs, device):\n",
    "    # Generate images\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        generated_imgs = model.decoder(torch.randn([n_imgs, model.latent_dim]).to(device))\n",
    "    generated_imgs = generated_imgs.cpu()\n",
    "\n",
    "    grid = torchvision.utils.make_grid(generated_imgs, nrow=4, normalize=False, range=(-1,1))\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    if len(input_imgs) == 4:\n",
    "        plt.figure(figsize=(10,10))\n",
    "    else:\n",
    "        plt.figure(figsize=(15,10))\n",
    "    plt.title(f\"Generations\")\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generate_images(vae, 16 , device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}